{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics         import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.preprocessing as sk_pp\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In assignment two, we used classification models to predict if the median earnings of a school's students exceeds $30.6k, which is the median value of the earnings in the training data. In this assignment, we will use random forest models to predict the same thing. However, the dimensionality of the model will be reduced. We want to know whether reduce dimensionality could increase the model accuracy.   \n",
    "\n",
    "Before we start, let's import the data and add flag variable as we did in assignment two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college = pickle.load(open(\"college.p\",\"rb\"))\n",
    "college_label = pickle.load(open(\"college_label.p\",\"rb\"))\n",
    "college_test = pickle.load(open(\"college_test.p\",\"rb\"))\n",
    "college_test_label = pickle.load(open(\"college_test_label.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quantiles = college_label.quantile(q=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def median_code(data):\n",
    "    if data < quantiles:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college_label_median = college_label.map(median_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college_test_label_median = college_test_label.map(median_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college_centered = college - college.mean(axis=0)\n",
    "college_test_centered = college_test - college.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choosing the right number of dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan to use PCA in Scikit-Learn to implements PCA. There is a very important argument that we need to specify when using the PCA, that is the number of dimensions to reduce down to. Instead of arbitrarily choosing a number, we would like to choose the number of dimensions that add up to a sufficiently large portion of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(college_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39044101,  0.20941999,  0.07755925,  0.05390012,  0.03532041,\n",
       "        0.03255564,  0.02523042,  0.02201691,  0.01682056,  0.01401534])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two components explanis close to 60% of the variances of the original dataset. Let's take a closer look at these two components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Features        E1            E2\n",
      "0   MedianFamilyIncome  0.504568  8.814541e-02\n",
      "1     DebtNonCompleter  0.381319 -1.293074e-01\n",
      "2             FirstGen -0.486701 -1.324599e-01\n",
      "3              IndPerc -0.424426 -3.250677e-01\n",
      "4             LoanPerc  0.127373 -6.345740e-01\n",
      "5             NetPrice  0.258141 -5.676994e-01\n",
      "6                   AK -0.132719 -2.402558e-01\n",
      "7                   AL  0.147133 -1.423529e-02\n",
      "8                   AR -0.014414  2.544911e-01\n",
      "9                   AS -0.048196  4.528846e-02\n",
      "10                  AZ  0.195082  5.741809e-03\n",
      "11                  CA -0.138619 -3.349732e-02\n",
      "12                  CO  0.001959 -4.597992e-07\n",
      "13                  CT -0.010226 -1.753249e-02\n",
      "14                  DC -0.000237  4.754260e-04\n",
      "15                  DE  0.000304  3.375011e-03\n",
      "16                  FL -0.001362  3.846081e-03\n",
      "17                  FM -0.000044  4.012223e-04\n",
      "18                  GA -0.003924 -5.350365e-03\n",
      "19                  GU -0.010737 -3.199662e-03\n",
      "20                  HI -0.001167 -3.618202e-03\n",
      "21                  IA  0.001492 -3.033132e-04\n",
      "22                  ID  0.000535 -6.036308e-04\n",
      "23                  IL  0.000098  2.084911e-05\n",
      "24                  IN -0.008908 -9.553390e-03\n",
      "25                  KS -0.000059  3.386966e-04\n",
      "26                  KY -0.000825  1.203518e-03\n",
      "27                  LA -0.000024  4.802486e-04\n",
      "28                  MA -0.000593  1.837788e-03\n",
      "29                  MD  0.003752  3.185473e-04\n",
      "..                 ...       ...           ...\n",
      "42                  NM -0.000062  3.741084e-04\n",
      "43                  NV -0.000594  3.883141e-03\n",
      "44                  NY  0.000376  2.383490e-03\n",
      "45                  OH -0.000285  5.326850e-03\n",
      "46                  OK  0.000637  2.064127e-03\n",
      "47                  OR  0.001961  1.806674e-03\n",
      "48                  PA  0.001884 -3.049823e-04\n",
      "49                  PR -0.001256 -1.665573e-03\n",
      "50                  PW -0.000848  3.306049e-03\n",
      "51                  RI -0.001187 -2.410279e-03\n",
      "52                  SC  0.012307  4.610141e-03\n",
      "53                  SD -0.000729 -1.242100e-02\n",
      "54                  TN -0.005301  8.100212e-03\n",
      "55                  TX  0.000959 -1.305808e-03\n",
      "56                  UT  0.010724 -1.099728e-02\n",
      "57                  VA -0.006275  1.965843e-02\n",
      "58                  VI -0.000035  3.849877e-04\n",
      "59                  VT  0.001592 -3.625775e-04\n",
      "60                  WA  0.001537  7.232831e-04\n",
      "61                  WI  0.001416  6.457848e-04\n",
      "62                  WV -0.002773  4.178217e-04\n",
      "63                  WY -0.013643 -3.856245e-04\n",
      "64  Private for-profit -0.000628 -1.297626e-03\n",
      "65   Private nonprofit  0.001058 -1.916605e-03\n",
      "66              Public -0.000005  2.429832e-04\n",
      "67    Associate-degree  0.002482 -5.189972e-04\n",
      "68     Bachelor-degree -0.000056  3.510479e-03\n",
      "69  Certificate-degree  0.003119 -1.194423e-03\n",
      "70     Graduate-degree -0.000340  2.325790e-03\n",
      "71       Not classfied -0.000232  7.388610e-04\n",
      "\n",
      "[72 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "E1, E2 = pd.DataFrame(pca.components_[0]), pd.DataFrame(pca.components_[1])\n",
    "eigenvectors = pd.concat([features,E1,E2],axis = 1)\n",
    "eigenvectors.columns = ['Features','E1','E2']\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first component is strongly correlated with *MedianFamilyIncome*, and *FirstGen*. To be more specific, the first component can be viewed as a measure of family impact. It increases if a campus has high median family income, and low percentage of students who are the first generation to be highly educated in their family.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second component is strongly correlated with *NetPrice* and *IndPerc*. This component can be viewed as a measure of the financial burden of students in that campus. If the campus has a low percent of financial independent student and high net price, indicating students have relative heavier financial burden, this componen will increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying PCA to predictive models, we need to find out the number of dimensions that add up to a sufficiently large portion of the variance. In our case, we want to know how many dimensions that could explain 90% or 95% of the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cumsum = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 25\n"
     ]
    }
   ],
   "source": [
    "d1 = np.argmax(cumsum >= 0.90) + 1\n",
    "d2 = np.argmax(cumsum >= 0.95) + 1\n",
    "print(d1, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, in the next steps, we will build random forest models with datasets contain 13 components and 25 components respectivily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Random Forest Model with 13 components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Random forest model with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=d1, random_state = 42)\n",
    "college_reduced = pca.fit_transform(college_centered)\n",
    "rf_clf = RandomForestClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance comparison on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_rf_reduced = cross_val_predict(rf_clf, college_reduced, college_label_median, cv=3)\n",
    "pred_rf = cross_val_predict(rf_clf, college, college_label_median, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.85      0.81      2403\n",
      "          1       0.83      0.74      0.79      2404\n",
      "\n",
      "avg / total       0.80      0.80      0.80      4807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest with PCA\\n' + classification_report(college_label_median, pred_rf_reduced)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.87      0.83      2403\n",
      "          1       0.86      0.78      0.82      2404\n",
      "\n",
      "avg / total       0.83      0.82      0.82      4807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest without PCA\\n' + classification_report(college_label_median, pred_rf)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification report, we can see that the random forest model without PCA outperforms the random forest model with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance comparison on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "college_test_reduced = pca.fit_transform(college_test_centered)\n",
    "rf_clf.fit(college_reduced, college_label_median)\n",
    "test_pred_reduced = rf_clf.predict(college_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.69      0.69       612\n",
      "          1       0.70      0.70      0.70       631\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest with PCA\\n' + classification_report(college_test_label_median,test_pred_reduced)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf.fit(college, college_label_median)\n",
    "test_pred = rf_clf.predict(college_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.92      0.89       612\n",
      "          1       0.91      0.85      0.88       631\n",
      "\n",
      "avg / total       0.89      0.88      0.88      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest without PCA\\n' + classification_report(college_test_label_median,test_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model performs even worse on the test set when we apply PCA to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.2 Random forest model with Kernel PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the kernel PCA is applied to the random forest model. We will use grid search to select the kernel and hyperparameters that lead to the best performance.  The whole process can be separate into two steps:  \n",
    "\n",
    "1. Reduce dimensionality to 13 dimensions using KPCA, then applying random forest classifier for classification. \n",
    "2. Use GridSearchCV to find the best kernel and gamma value for kPCA in order to get the best classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('kpca', KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "     fit_inverse_transform=False, gamma=None, kernel='linear',\n",
       "     kernel_params=None, max_iter=None, n_components=13, n_jobs=1,\n",
       "     random_state=42, remove_zero_eig=False, tol=0)), ('rf_clf', RandomForestCla...stimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kpca__kernel': ['rbf', 'sigmoid', 'poly'], 'kpca__gamma': array([ 0.05 ,  0.075,  0.1  ,  0.125,  0.15 ])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "        ('kpca', KernelPCA(n_components=13, random_state = 42)),\n",
    "        ('rf_clf', RandomForestClassifier(random_state = 42))\n",
    "    ])\n",
    "\n",
    "param_grid = [{\n",
    "        \"kpca__gamma\" : np.linspace(0.05, 0.15, 5 ),\n",
    "        \"kpca__kernel\" :['rbf', 'sigmoid','poly']\n",
    "    }]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv = 3, scoring = 'accuracy')\n",
    "grid_search.fit(college_reduced, college_label_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kpca__kernel': 'rbf', 'kpca__gamma': 0.050000000000000003}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the above parameters to build a random forest model with kernal PCA applied on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('kpca', KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "     fit_inverse_transform=False, gamma=0.05, kernel='rbf',\n",
       "     kernel_params=None, max_iter=None, n_components=13, n_jobs=1,\n",
       "     random_state=42, remove_zero_eig=False, tol=0)), ('rf_clf', RandomForestClassi...stimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "        ('kpca', KernelPCA(n_components=13, random_state = 42, gamma=0.05, kernel='rbf')),\n",
    "        ('rf_clf', RandomForestClassifier(random_state = 42))\n",
    "    ])\n",
    "clf.fit(college_centered, college_label_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Performance on training set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Kernel PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.86      0.82      2403\n",
      "          1       0.84      0.77      0.80      2404\n",
      "\n",
      "avg / total       0.81      0.81      0.81      4807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_pred = cross_val_predict(clf, college_centered, college_label_median)\n",
    "print('Random Forest with Kernel PCA\\n' + classification_report(college_label_median,clf_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is still worse than the random forest model without kernel PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Performance on test set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Kernel PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.89      0.86       612\n",
      "          1       0.88      0.83      0.85       631\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_pred_test = clf.predict(college_test_centered)\n",
    "print('Random Forest with Kernel PCA\\n' + classification_report(college_test_label_median,clf_pred_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel PCA works better than linear PCA in the random forest model. But random forest model with complete dimensionality is still the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Random Forest Model with 25 components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
