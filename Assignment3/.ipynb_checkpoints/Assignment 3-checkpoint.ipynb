{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load required packages\n",
    "import pickle\n",
    "from sklearn.metrics         import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.preprocessing as sk_pp\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In assignment two, we used classification models to predict if the median earning of a school's students exceeds $30.6k. In this assignment, we will use random forest models to predict the same thing. However, the dimensionality of the model will be reduced. We want to know whether the reduction in dimensionality could increase the model accuracy.   \n",
    "\n",
    "Before we start, let's import the data and add flag variable as we did in assignment two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "college = pickle.load(open(\"college.p\",\"rb\"))\n",
    "college_label = pickle.load(open(\"college_label.p\",\"rb\"))\n",
    "college_test = pickle.load(open(\"college_test.p\",\"rb\"))\n",
    "college_test_label = pickle.load(open(\"college_test_label.p\",\"rb\"))\n",
    "features = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quantiles = college_label.quantile(q=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def median_code(data):\n",
    "    if data < quantiles:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college_label_median = college_label.map(median_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college_test_label_median = college_test_label.map(median_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college_centered = college - college.mean(axis=0)\n",
    "college_test_centered = college_test - college.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choosing the right number of dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plan to use PCA in Scikit-Learn to implement PCA. There is a very important argument that we need to specify when using the PCA - the number of dimensions to reduce to. Instead of choosing an arbitrary number, we would like to choose the number of dimensions that add up to a sufficiently large portion of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(college_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39044101,  0.20941999,  0.07755925,  0.05390012,  0.03532041,\n",
       "        0.03255564,  0.02523042,  0.02201691,  0.01682056,  0.01401534])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two components explains about 60% of the variance of the original X variables. Let's take a closer look at these two components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Features        E1            E2\n",
      "0   MedianFamilyIncome  0.504568  8.814541e-02\n",
      "1     DebtNonCompleter  0.381319 -1.293074e-01\n",
      "2             FirstGen -0.486701 -1.324599e-01\n",
      "3              IndPerc -0.424426 -3.250677e-01\n",
      "4             LoanPerc  0.127373 -6.345740e-01\n",
      "5             NetPrice  0.258141 -5.676994e-01\n",
      "6                   AK -0.132719 -2.402558e-01\n",
      "7                   AL  0.147133 -1.423529e-02\n",
      "8                   AR -0.014414  2.544911e-01\n",
      "9                   AS -0.048196  4.528846e-02\n",
      "10                  AZ  0.195082  5.741809e-03\n",
      "11                  CA -0.138619 -3.349732e-02\n",
      "12                  CO  0.001959 -4.598247e-07\n",
      "13                  CT -0.010226 -1.753249e-02\n",
      "14                  DC -0.000237  4.754260e-04\n",
      "15                  DE  0.000304  3.375011e-03\n",
      "16                  FL -0.001362  3.846081e-03\n",
      "17                  FM -0.000044  4.012223e-04\n",
      "18                  GA -0.003924 -5.350365e-03\n",
      "19                  GU -0.010737 -3.199662e-03\n"
     ]
    }
   ],
   "source": [
    "E1, E2 = pd.DataFrame(pca.components_[0]), pd.DataFrame(pca.components_[1])\n",
    "eigenvectors = pd.concat([features,E1,E2],axis = 1)\n",
    "eigenvectors.columns = ['Features','E1','E2']\n",
    "print(eigenvectors.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first component is strongly correlated with `MedianFamilyIncome`, and `FirstGen`. To be more specific, the first component can be viewed as a measure of family impact. It increases if a campus has high median family income, and low percentage of students who are the first one to receive higher education in their family.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second component is strongly correlated with `NetPrice` and `IndPerc`. This component can be viewed as a measure of the financial burden of students in that campus. If the campus has a low percent of financial independent student and high net price, indicating students have a relatively heavier financial burden, this component will increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying PCA to predictive models, we need to find out the number of dimensions that add up to a sufficiently large portion of the variance. In our case, we want to know how many dimensions that could explain 90% and 95% of the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cumsum = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 25\n"
     ]
    }
   ],
   "source": [
    "d1 = np.argmax(cumsum >= 0.90) + 1\n",
    "d2 = np.argmax(cumsum >= 0.95) + 1\n",
    "print(d1, d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, for the next step, we will build random forest models using 13 components and 25 components respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Random Forest Model with 13 components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Random forest model with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=d1, random_state = 42)\n",
    "college_reduced = pca.fit_transform(college_centered)\n",
    "rf_clf = RandomForestClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance comparison on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_rf_reduced = cross_val_predict(rf_clf, college_reduced, college_label_median, cv=3)\n",
    "pred_rf = cross_val_predict(rf_clf, college, college_label_median, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with 13 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.85      0.81      2403\n",
      "          1       0.83      0.74      0.79      2404\n",
      "\n",
      "avg / total       0.80      0.80      0.80      4807\n",
      "\n",
      "Random Forest without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.87      0.83      2403\n",
      "          1       0.86      0.78      0.82      2404\n",
      "\n",
      "avg / total       0.83      0.82      0.82      4807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest with 13 PC\\n' + classification_report(college_label_median, pred_rf_reduced))\n",
    "print('Random Forest without PCA\\n' + classification_report(college_label_median, pred_rf)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the classification report, we can see that the random forest model without PCA outperforms the random forest model with PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance comparison on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "college_test_reduced = pca.fit_transform(college_test_centered)\n",
    "rf_clf.fit(college_reduced, college_label_median)\n",
    "test_pred_reduced = rf_clf.predict(college_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_clf.fit(college, college_label_median)\n",
    "test_pred = rf_clf.predict(college_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with 13 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.69      0.69       612\n",
      "          1       0.70      0.70      0.70       631\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1243\n",
      "\n",
      "Random Forest without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.92      0.89       612\n",
      "          1       0.91      0.85      0.88       631\n",
      "\n",
      "avg / total       0.89      0.88      0.88      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest with 13 PC\\n' + classification_report(college_test_label_median,test_pred_reduced)) \n",
    "print('Random Forest without PCA\\n' + classification_report(college_test_label_median,test_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model performs even worse on the test set when we apply PCA to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.2 Random forest model with Kernel PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, the kernel PCA is applied to the random forest model. We will use grid search to select the kernel and hyperparameters that lead to the best performance.  The whole process can be separate into two steps:  \n",
    "\n",
    "1. Reduce dimensionality to 13 dimensions using KPCA, then applying random forest classifier for classification. \n",
    "2. Use GridSearchCV to find the best kernel and gamma value for KPCA in order to get the best classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('kpca', KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "     fit_inverse_transform=False, gamma=None, kernel='linear',\n",
       "     kernel_params=None, max_iter=None, n_components=13, n_jobs=1,\n",
       "     random_state=42, remove_zero_eig=False, tol=0)), ('rf_clf', RandomForestCla...stimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kpca__kernel': ['rbf', 'sigmoid', 'poly'], 'kpca__gamma': array([ 0.05,  0.07,  0.09,  0.11,  0.13,  0.15])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "        ('kpca', KernelPCA(n_components=13, random_state = 42)),\n",
    "        ('rf_clf', RandomForestClassifier(random_state = 42))\n",
    "    ])\n",
    "\n",
    "param_grid = [{\n",
    "        \"kpca__gamma\" : np.linspace(0.05, 0.15, 6),\n",
    "        \"kpca__kernel\" :['rbf', 'sigmoid','poly']\n",
    "    }]\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv = 3, scoring = 'accuracy')\n",
    "grid_search.fit(college_reduced, college_label_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kpca__kernel': 'sigmoid', 'kpca__gamma': 0.089999999999999997}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the above parameters to build a random forest model with kernal PCA applied on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('kpca', KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "     fit_inverse_transform=False, gamma=0.09, kernel='sigmoid',\n",
       "     kernel_params=None, max_iter=None, n_components=13, n_jobs=1,\n",
       "     random_state=42, remove_zero_eig=False, tol=0)), ('rf_clf', RandomForestCl...stimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "        ('kpca', KernelPCA(n_components=13, random_state = 42, gamma=0.09, kernel='sigmoid')),\n",
    "        ('rf_clf', RandomForestClassifier(random_state = 42))\n",
    "    ])\n",
    "clf.fit(college_centered, college_label_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Performance on training set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Kernel PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.84      0.80      2403\n",
      "          1       0.83      0.74      0.78      2404\n",
      "\n",
      "avg / total       0.80      0.79      0.79      4807\n",
      "\n",
      "Random Forest with 13 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.69      0.69       612\n",
      "          1       0.70      0.70      0.70       631\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1243\n",
      "\n",
      "Random Forest without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.92      0.89       612\n",
      "          1       0.91      0.85      0.88       631\n",
      "\n",
      "avg / total       0.89      0.88      0.88      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_pred = cross_val_predict(clf, college_centered, college_label_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Kernel 13 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.84      0.80      2403\n",
      "          1       0.83      0.74      0.78      2404\n",
      "\n",
      "avg / total       0.80      0.79      0.79      4807\n",
      "\n",
      "Random Forest with 13 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.69      0.69       612\n",
      "          1       0.70      0.70      0.70       631\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1243\n",
      "\n",
      "Random Forest without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.92      0.89       612\n",
      "          1       0.91      0.85      0.88       631\n",
      "\n",
      "avg / total       0.89      0.88      0.88      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest with Kernel 13 PC\\n' + classification_report(college_label_median,clf_pred))\n",
    "print('Random Forest with 13 PC\\n' + classification_report(college_test_label_median,test_pred_reduced)) \n",
    "print('Random Forest without PCA\\n' + classification_report(college_test_label_median,test_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is still worse than the random forest model without kernel PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Performance on test set **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Kernel PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.90      0.87       612\n",
      "          1       0.90      0.83      0.86       631\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_pred_test = clf.predict(college_test_centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Kernel 13 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.90      0.87       612\n",
      "          1       0.90      0.83      0.86       631\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1243\n",
      "\n",
      "Random Forest with 13 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.69      0.69       612\n",
      "          1       0.70      0.70      0.70       631\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1243\n",
      "\n",
      "Random Forest without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.92      0.89       612\n",
      "          1       0.91      0.85      0.88       631\n",
      "\n",
      "avg / total       0.89      0.88      0.88      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest with Kernel 13 PC\\n' + classification_report(college_test_label_median,clf_pred_test))\n",
    "print('Random Forest with 13 PC\\n' + classification_report(college_test_label_median,test_pred_reduced)) \n",
    "print('Random Forest without PCA\\n' + classification_report(college_test_label_median,test_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The kernel PCA works better than linear PCA in the random forest model. But random forest model with complete dimensionality is still the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Random Forest Model with 25 components "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building a random forest model with 13 principal conponents, we also would liket to see if the model accuracy will improve if we increase the number of principal components used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.1 Ramdon Forest with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we transform original variables into 25 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#25 components\n",
    "pca1 = PCA(n_components=d2, random_state = 42)\n",
    "college_reduced1 = pca1.fit_transform(college_centered)\n",
    "rf_clf1 = RandomForestClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance comparison on training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let'e evaluate the model performance on training data and compare the result with that of 13 principal components and that without principal component analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_rf_reduced1 = cross_val_predict(rf_clf1, college_reduced1, college_label_median, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.87      0.83      2403\n",
      "          1       0.86      0.78      0.82      2404\n",
      "\n",
      "avg / total       0.83      0.82      0.82      4807\n",
      "\n",
      "Random Forest with 13 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.85      0.81      2403\n",
      "          1       0.83      0.74      0.79      2404\n",
      "\n",
      "avg / total       0.80      0.80      0.80      4807\n",
      "\n",
      "Random Forest with 25 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79      2403\n",
      "          1       0.82      0.70      0.75      2404\n",
      "\n",
      "avg / total       0.78      0.77      0.77      4807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest without PCA\\n' + classification_report(college_label_median, pred_rf))\n",
    "print('Random Forest with 13 PC\\n' + classification_report(college_label_median, pred_rf_reduced))\n",
    "print('Random Forest with 25 PC\\n' + classification_report(college_label_median, pred_rf_reduced1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that models with 25 components performs worse than that with 13 components on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "college_test_reduced1 = pca1.fit_transform(college_test_centered)\n",
    "rf_clf1.fit(college_reduced1, college_label_median)\n",
    "test_pred_reduced1 = rf_clf1.predict(college_test_reduced1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with 25 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.72      0.69       612\n",
      "          1       0.71      0.66      0.68       631\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1243\n",
      "\n",
      "Random Forest with 13 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.69      0.69       612\n",
      "          1       0.70      0.70      0.70       631\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1243\n",
      "\n",
      "Random Forest without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.92      0.89       612\n",
      "          1       0.91      0.85      0.88       631\n",
      "\n",
      "avg / total       0.89      0.88      0.88      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest with 25 PC\\n' + classification_report(college_test_label_median,test_pred_reduced1))\n",
    "print('Random Forest with 13 PC\\n' + classification_report(college_test_label_median,test_pred_reduced))\n",
    "print('Random Forest without PCA\\n' + classification_report(college_test_label_median,test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the 25-component solution has worse performance than the 13-component solution and the model without PCA. Then let's see if using Kernal PCA is going to improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Random forest model with Kernel PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do Kernal PCA with 25 components and use GridSearchCV to find the best kernel and gamma value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('kpca', KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "     fit_inverse_transform=False, gamma=None, kernel='linear',\n",
       "     kernel_params=None, max_iter=None, n_components=25, n_jobs=1,\n",
       "     random_state=42, remove_zero_eig=False, tol=0)), ('rf_clf', RandomForestCla...stimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'kpca__kernel': ['rbf', 'sigmoid', 'poly'], 'kpca__gamma': array([ 0.05,  0.07,  0.09,  0.11,  0.13,  0.15])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = Pipeline([\n",
    "        ('kpca', KernelPCA(n_components=25, random_state = 42)),\n",
    "        ('rf_clf', RandomForestClassifier(random_state = 42))\n",
    "    ])\n",
    "\n",
    "param_grid1 = [{\n",
    "        \"kpca__gamma\" : np.linspace(0.05, 0.15, 6),\n",
    "        \"kpca__kernel\" :['rbf', 'sigmoid','poly']\n",
    "    }]\n",
    "\n",
    "grid_search1 = GridSearchCV(clf1, param_grid1, cv = 3, scoring = 'accuracy')\n",
    "grid_search1.fit(college_reduced, college_label_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kpca__kernel': 'poly', 'kpca__gamma': 0.14999999999999999}\n"
     ]
    }
   ],
   "source": [
    "print(grid_search1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best kernel is `poly` and the best gamma value is `0.15`. Then we build a random forest model with the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('kpca', KernelPCA(alpha=1.0, coef0=1, copy_X=True, degree=3, eigen_solver='auto',\n",
       "     fit_inverse_transform=False, gamma=0.15, kernel='poly',\n",
       "     kernel_params=None, max_iter=None, n_components=25, n_jobs=1,\n",
       "     random_state=42, remove_zero_eig=False, tol=0)), ('rf_clf', RandomForestClass...stimators=10, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = Pipeline([\n",
    "        ('kpca', KernelPCA(n_components=25, random_state = 42, gamma=0.15, kernel='poly')),\n",
    "        ('rf_clf', RandomForestClassifier(random_state = 42))\n",
    "    ])\n",
    "clf1.fit(college_centered, college_label_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Kernel PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.84      0.80      2403\n",
      "          1       0.83      0.74      0.78      2404\n",
      "\n",
      "avg / total       0.80      0.79      0.79      4807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_pred1 = cross_val_predict(clf1, college_centered, college_label_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Kernel 25 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.84      0.80      2403\n",
      "          1       0.83      0.74      0.78      2404\n",
      "\n",
      "avg / total       0.80      0.79      0.79      4807\n",
      "\n",
      "Random Forest with 25 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79      2403\n",
      "          1       0.82      0.70      0.75      2404\n",
      "\n",
      "avg / total       0.78      0.77      0.77      4807\n",
      "\n",
      "Random Forest with Kernel 13 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.84      0.80      2403\n",
      "          1       0.83      0.74      0.78      2404\n",
      "\n",
      "avg / total       0.80      0.79      0.79      4807\n",
      "\n",
      "Random Forest without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.87      0.83      2403\n",
      "          1       0.86      0.78      0.82      2404\n",
      "\n",
      "avg / total       0.83      0.82      0.82      4807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest with Kernel 25 PC\\n' + classification_report(college_label_median, clf_pred1)) \n",
    "print('Random Forest with 25 PC\\n' + classification_report(college_label_median, pred_rf_reduced1))\n",
    "print('Random Forest with Kernel 13 PC\\n' + classification_report(college_label_median,clf_pred))\n",
    "print('Random Forest without PCA\\n' + classification_report(college_label_median, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of model with 25 components using Kernel PCA is better than PCA without Kernel and it performs as well as 13-component solution with kernel. Still, the random forest model without PCA is the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Kernel 25 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.89      0.86       612\n",
      "          1       0.88      0.83      0.86       631\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1243\n",
      "\n",
      "Random Forest with 25 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.72      0.69       612\n",
      "          1       0.71      0.66      0.68       631\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1243\n",
      "\n",
      "Random Forest without PCA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.92      0.89       612\n",
      "          1       0.91      0.85      0.88       631\n",
      "\n",
      "avg / total       0.89      0.88      0.88      1243\n",
      "\n",
      "Random Forest with Kernel 13 PC\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.90      0.87       612\n",
      "          1       0.90      0.83      0.86       631\n",
      "\n",
      "avg / total       0.87      0.87      0.87      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_pred_test1 = clf1.predict(college_test_centered)\n",
    "print('Random Forest with Kernel 25 PC\\n' + classification_report(college_test_label_median,clf_pred_test1))\n",
    "print('Random Forest with 25 PC\\n' + classification_report(college_test_label_median,test_pred_reduced1))\n",
    "print('Random Forest without PCA\\n' + classification_report(college_test_label_median,test_pred))\n",
    "print('Random Forest with Kernel 13 PC\\n' + classification_report(college_test_label_median,clf_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see similar performance on the testing data. The 25-component solution with Kernel is better than the solution without kernel but still worse than the model without PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis above, we see that performing PCA doesn't necessarily improve the performance of the model in this specific case. \n",
    "\n",
    "We use 13 components and 25 components to build random forest models and the 13-component solution seems to perform better than 25-component solution. Also, doing PCA with Kernel improves the the accuracy of the model. Although PCA doesn't increase the model accuracy in this specific case. It gives us a better understanding of how factors relate to each other and helps reduce the model complexity. \n",
    "\n",
    "With further research, we realize that PCA is not always a good method to use when building predictive model. It could increase the performance in some cases but could decrease model performance in other cases. The conclusion is that we had better use PCA when the dimension of data is large and we want to reduce the variables we include in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
