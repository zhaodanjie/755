{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA755 College Scoreboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source:  \n",
    "Group Members: Stacy Li, Danjie Zhao, Sylvia Gao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the csv file for 2012-2013, which is the most recent dataset that contains earning information. NA value in the dataset is indicated by `NULL`. However, since we have no way to know the information in the cell labeled as `PrivacySuppressed`, we also include it in NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stact/anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"MERGED2012_13_PP.csv\", header = 0, na_values = [\"NULL\",\"PrivacySuppressed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>﻿UNITID</th>\n",
       "      <th>OPEID</th>\n",
       "      <th>OPEID6</th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>ACCREDAGENCY</th>\n",
       "      <th>INSTURL</th>\n",
       "      <th>NPCURL</th>\n",
       "      <th>...</th>\n",
       "      <th>D100_L4</th>\n",
       "      <th>TRANS_4</th>\n",
       "      <th>DTRANS_4</th>\n",
       "      <th>TRANS_L4</th>\n",
       "      <th>DTRANS_L4</th>\n",
       "      <th>ICLEVEL</th>\n",
       "      <th>UGDS_MEN</th>\n",
       "      <th>UGDS_WOMEN</th>\n",
       "      <th>CDR3_DENOM</th>\n",
       "      <th>CDR2_DENOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654</td>\n",
       "      <td>100200</td>\n",
       "      <td>1002</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>35762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4879</td>\n",
       "      <td>0.5121</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>1574.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100663</td>\n",
       "      <td>105200</td>\n",
       "      <td>1052</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>35294-0110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.290236</td>\n",
       "      <td>1485.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>3153.0</td>\n",
       "      <td>3481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100690</td>\n",
       "      <td>2503400</td>\n",
       "      <td>25034</td>\n",
       "      <td>Amridge University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>36117-3553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>0.5621</td>\n",
       "      <td>264.0</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100706</td>\n",
       "      <td>105500</td>\n",
       "      <td>1055</td>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>AL</td>\n",
       "      <td>35899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307116</td>\n",
       "      <td>801.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5425</td>\n",
       "      <td>0.4575</td>\n",
       "      <td>1208.0</td>\n",
       "      <td>1392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100724</td>\n",
       "      <td>100500</td>\n",
       "      <td>1005</td>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>36104-0271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1298.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1961.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1743 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ﻿UNITID    OPEID  OPEID6                               INSTNM        CITY  \\\n",
       "0   100654   100200    1002             Alabama A & M University      Normal   \n",
       "1   100663   105200    1052  University of Alabama at Birmingham  Birmingham   \n",
       "2   100690  2503400   25034                   Amridge University  Montgomery   \n",
       "3   100706   105500    1055  University of Alabama in Huntsville  Huntsville   \n",
       "4   100724   100500    1005             Alabama State University  Montgomery   \n",
       "\n",
       "  STABBR         ZIP  ACCREDAGENCY  INSTURL  NPCURL     ...      D100_L4  \\\n",
       "0     AL       35762           NaN      NaN     NaN     ...          NaN   \n",
       "1     AL  35294-0110           NaN      NaN     NaN     ...          NaN   \n",
       "2     AL  36117-3553           NaN      NaN     NaN     ...          NaN   \n",
       "3     AL       35899           NaN      NaN     NaN     ...          NaN   \n",
       "4     AL  36104-0271           NaN      NaN     NaN     ...          NaN   \n",
       "\n",
       "    TRANS_4  DTRANS_4  TRANS_L4  DTRANS_L4  ICLEVEL  UGDS_MEN  UGDS_WOMEN  \\\n",
       "0  0.000000    1133.0       NaN        NaN        1    0.4879      0.5121   \n",
       "1  0.290236    1485.0       NaN        NaN        1    0.4200      0.5800   \n",
       "2  0.000000       1.0       NaN        NaN        1    0.4379      0.5621   \n",
       "3  0.307116     801.0       NaN        NaN        1    0.5425      0.4575   \n",
       "4  0.000000    1298.0       NaN        NaN        1    0.4046      0.5954   \n",
       "\n",
       "   CDR3_DENOM  CDR2_DENOM  \n",
       "0      1405.0      1574.0  \n",
       "1      3153.0      3481.0  \n",
       "2       264.0       336.0  \n",
       "3      1208.0      1392.0  \n",
       "4      1951.0      1961.0  \n",
       "\n",
       "[5 rows x 1743 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() #take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to build a model to predict student's earning in the long term. So among all variables for earning, we select **median earning 10 years after entry** as our target variable. Given target variable we would like to predict, we manually selected 10 variables,  with one or two in each categories,that may be predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#only select 10 variables that interest us\n",
    "data_filter = data[['\\ufeffUNITID',\"OPEID\",\"MD_FAMINC\", \"WDRAW_DEBT_MDN\" , \"PREDDEG\", \"STABBR\",\n",
    "\"NPT4_PUB\", \"NPT4_PRIV\", \"PAR_ED_PCT_1STGEN\", \"DEP_STAT_PCT_IND\", \"PCTFLOAN\", \"MD_EARN_WNE_P10\", \"CONTROL\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net price(estimated cost minus granted scholarship) is used to measure living cost for students in each school. But the net price information is recorded separatly in two columns in the original dataset, so we combine these two columns together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stact/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/stact/anaconda/lib/python3.5/site-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/stact/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#combine netprice for public school and private school together\n",
    "data_filter['NPT4_COMBINE'] =  data_filter['NPT4_PRIV']  \n",
    "data_filter.loc[data_filter['NPT4_COMBINE'].isnull(),'NPT4_COMBINE'] =  data_filter.loc[data_filter['NPT4_COMBINE'].isnull(),'NPT4_PUB']\n",
    "data_filter.drop([\"NPT4_PUB\",\"NPT4_PRIV\"],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_filter.columns = ['CampusID', 'InstitutionID','MedianFamilyIncome','DebtNonCompleter',\n",
    "                      'PredominantDegree','State','FirstGen','IndPerc','LoanPerc','MDEarning10','Control','NetPrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our goal is to predict **median income 10 years after entry**, the next step would be to remove rows without this variable to ensure prediction accuracy. Rows lacking this variable can be saved for later prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing = data_filter.loc[data_filter[\"MDEarning10\"].isnull(),:]\n",
    "non_missing = data_filter.loc[~data_filter[\"MDEarning10\"].isnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CampusID               0.000000\n",
       "InstitutionID          0.000000\n",
       "MedianFamilyIncome     0.462810\n",
       "DebtNonCompleter      10.429752\n",
       "PredominantDegree      0.000000\n",
       "State                  0.000000\n",
       "FirstGen               3.702479\n",
       "IndPerc                2.082645\n",
       "LoanPerc               7.140496\n",
       "MDEarning10            0.000000\n",
       "Control                0.000000\n",
       "NetPrice              10.561983\n",
       "dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing rate of each variable\n",
    "non_missing.isnull().mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import hashlib package\n",
    "import hashlib\n",
    "\n",
    "#define test_set_check function to compute a hash of each instance's indentifier\n",
    "def test_set_check(identifier, test_ratio, hash):\n",
    "    #put the instance in the test set if the value is lower or equal to 51=20%*256\n",
    "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio\n",
    "\n",
    "#Get the test and traning dataset based on the result of test_set_check() function\n",
    "def split_train_test_by_id(data, test_ratio, id_column, hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio, hash))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#split training dataset and test dataset by the newly created id column\n",
    "train_set, test_set = split_train_test_by_id(non_missing, 0.2, \"CampusID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing some exploratory analysis, we have gained some insights into the dataset and identify several variables that may be useful for prediction such as median income and ocean proximity. Before proceeding to the modeling stage, we need to first prepare a clean dataset to feed into model, which requires us to do something about missing values and encode categorical variables to numerical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First separate predictors and prediction label into two dataset, so that we can deal with the missing value in predictors without interrupting response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4807, 11)\n",
      "(4807,)\n"
     ]
    }
   ],
   "source": [
    "college = train_set.drop(\"MDEarning10\", axis=1) #drop this column\n",
    "college_labels = train_set[\"MDEarning10\"].copy()\n",
    "print(college.shape)\n",
    "print(college_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting two separate dataset for predictors and response variable. We can start off with data cleaning. Here, we decide to use median value of the column to replace missing values since the missing rate is not very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy = 'median') #create a empty transformer with specified strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns not useful for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college.drop([\"CampusID\",\"InstitutionID\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "college_num = college.drop(['State', 'PredominantDegree','Control'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the transform to the dataset only containing numerical variables. Median value of each columns are estimated, which will later be used to perform transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(college_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the parameter estimated to perform transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = imputer.transform(college_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a numpy array, so we need to convert is back to pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college_tr = pd.DataFrame(X, columns = college_num.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three categorical variables in the dataset: State, PredominantDegree, Control. They are all nominal variables, so we use `LabelBinarizer` transform to encode them into dummy variables. However, `LabelBinarized` can only accept one column as input, so I modify the transformer to allow multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "college_cat = college[['State', 'PredominantDegree','Control']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a custom transformer `EncodeCategorical` to allow us to code multiple categorical variables into dummier at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EncodeCategorical(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Encodes a specified list of columns or all columns if None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns  = columns\n",
    "        self.encoders = None\n",
    "\n",
    "    def fit(self, data, target=None):\n",
    "        \"\"\"\n",
    "        Expects a data frame with named columns to encode.\n",
    "        \"\"\"\n",
    "        # Encode all columns if columns is None\n",
    "        if self.columns is None:\n",
    "            self.columns = data.columns\n",
    "\n",
    "        # Fit a label encoder for each column in the data frame\n",
    "        self.encoders = {\n",
    "            column: LabelBinarizer().fit(data[column])\n",
    "            for column in self.columns\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Uses the encoders to transform a data frame.\n",
    "        \"\"\"\n",
    "        output = np.empty([4807,0])\n",
    "        for column, encoder in self.encoders.items():\n",
    "             ay = encoder.transform(data[column])\n",
    "             output = np.concatenate((output, ay), axis = 1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4807"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(college)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder = EncodeCategorical(columns = ['State', 'PredominantDegree','Control'])\n",
    "college_cat_tr = encoder.fit_transform(college)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a numpy array with a size (4807, 66). All variables are dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4807, 66)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_cat_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Then we can create a Pipeline to accommodate all the estimators and execute them in a sequence, which would make the modeling process more automated and easy to manage. It should be noted that all but the last estimators should be transformers which have fit_transform() method. When we call fit_transform() method, the output of each estimators is fed into next estimator, until the end of pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a estimator used to select variables of the same type, so that we can divide the processing of numerical variables and categorical variabls into two sub pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin): #include BaseEstimator and TransformerMixin as base class\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names \n",
    "    def fit(self, X, y=None):  #Don't have to estimate any parameter, so no action\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to construct a full pipeline. The full pipeline consists of two parallel pipeline, one for categorical variables and one for numerical variables. At the beginning of each parallel pipeline, the `DataFrameSelector` is used to select only columns that we would like feed into the pipeline. At the end of pipeline, we use `FeatureUnion` function to combine two output together to form a clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "num_attribs = college_num.columns\n",
    "cat_attribs = ['State', 'PredominantDegree','Control']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector',DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy = 'median')),\n",
    "        ('std_scaler', StandardScaler()), \n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('select', DataFrameSelector(cat_attribs)),\n",
    "        ('label_binarizer', EncodeCategorical())\n",
    "    ])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        ('num_pipeline', num_pipeline),\n",
    "        ('cat_pipeline', cat_pipeline),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the full pipeline on the college data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4807, 72)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "college_prepared = full_pipeline.fit_transform(college)\n",
    "college_prepared.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the pipelinw has a shape of (4807, 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
